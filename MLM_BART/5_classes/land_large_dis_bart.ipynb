{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EkGB8Et2apg"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-score"
      ],
      "metadata": {
        "id": "nz2VKLQi48il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "JXiOadTTeSFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n"
      ],
      "metadata": {
        "id": "2qWA636m7Bn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "W8Wfq0th2hPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON dataset\n",
        "output_json = \"/content/drive/MyDrive/umich 25 WN/CSE 692 Project/BART/DATASET/5class_Land_larger_dis.json\"\n"
      ],
      "metadata": {
        "id": "0HaeX3zW2ocU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from datasets import Dataset, DatasetDict\n",
        "import json\n",
        "\n",
        "import random\n",
        "\n",
        "# Load pretrained BART model and tokenizer\n",
        "model_name = \"facebook/bart-large\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Add \"PFAS\" as a special token\n",
        "special_tokens = [\"PFAS\"]\n",
        "tokenizer.add_tokens(special_tokens)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "with open(output_json, \"r\", encoding=\"utf-8\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "# Shuffle for randomness\n",
        "random.shuffle(dataset)\n",
        "\n",
        "# Track already used original sentences\n",
        "used_originals = set()\n",
        "\n",
        "# Store selected examples by category\n",
        "discharger_data = []\n",
        "landcover_data = []\n",
        "label_data = []\n",
        "\n",
        "\n",
        "\n",
        "# How many samples per category to target\n",
        "target_per_category = len(dataset) // 3\n",
        "extra = len(dataset) - target_per_category * 3\n",
        "\n",
        "for item in dataset:\n",
        "    orig = item[\"original\"]\n",
        "\n",
        "    if orig in used_originals:\n",
        "        continue\n",
        "\n",
        "    if \"masked_discharger\" in item and len(discharger_data) < target_per_category:\n",
        "        discharger_data.append({\"input_text\": item[\"masked_discharger\"], \"target_text\": orig})\n",
        "        used_originals.add(orig)\n",
        "    elif \"masked_landcover\" in item and len(landcover_data) < target_per_category:\n",
        "        landcover_data.append({\"input_text\": item[\"masked_landcover\"], \"target_text\": orig})\n",
        "        used_originals.add(orig)\n",
        "    elif \"masked_label\" in item and len(label_data) < target_per_category:\n",
        "        label_data.append({\"input_text\": item[\"masked_label\"], \"target_text\": orig})\n",
        "        used_originals.add(orig)\n",
        "\n",
        "    # Once we reach the total, stop\n",
        "    if len(discharger_data) + len(landcover_data) + len(label_data) >= 407:\n",
        "        break\n",
        "\n",
        "# If there's still room (e.g., 200*3 = 600, need 2 more), fill from any category\n",
        "remaining = len(dataset) - (len(discharger_data) + len(landcover_data) + len(label_data))\n",
        "if remaining > 0:\n",
        "    remaining_data = []\n",
        "    for item in dataset:\n",
        "        orig = item[\"original\"]\n",
        "        if orig in used_originals:\n",
        "            continue\n",
        "        if \"masked_label\" in item:\n",
        "            remaining_data.append({\"input_text\": item[\"masked_label\"], \"target_text\": orig})\n",
        "        elif \"masked_discharger\" in item:\n",
        "            remaining_data.append({\"input_text\": item[\"masked_discharger\"], \"target_text\": orig})\n",
        "        elif \"masked_landcover\" in item:\n",
        "            remaining_data.append({\"input_text\": item[\"masked_landcover\"], \"target_text\": orig})\n",
        "        if len(remaining_data) >= remaining:\n",
        "            break\n",
        "\n",
        "# Final dataset\n",
        "hf_data = discharger_data + landcover_data + label_data + remaining_data\n",
        "random.shuffle(hf_data)  # shuffle for randomness\n"
      ],
      "metadata": {
        "id": "xzkOCWsN2v68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKf9crA0-3Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Hugging Face Dataset format\n",
        "hf_dataset = Dataset.from_list(hf_data)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    model_inputs = tokenizer(\n",
        "        examples[\"input_text\"],\n",
        "        text_target=examples[\"target_text\"],\n",
        "        max_length=256,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    labels = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
        "        for label in model_inputs[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": model_inputs[\"input_ids\"],\n",
        "        \"attention_mask\": model_inputs[\"attention_mask\"],\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "\n",
        "tokenized_dataset = hf_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"input_text\", \"target_text\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "nFwsi3wf9m_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "qHfaWQrsEPBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "train_val_dataset = split_dataset[\"train\"].train_test_split(test_size=0.125)\n",
        "\n",
        "train_dataset = train_val_dataset[\"train\"]\n",
        "val_dataset = train_val_dataset[\"test\"]\n",
        "test_dataset = split_dataset[\"test\"]\n"
      ],
      "metadata": {
        "id": "0oy180WK-pGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "\n",
        "import sys\n",
        "\n",
        "model.generation_config.early_stopping = True\n",
        "model.generation_config.num_beams = 4\n",
        "model.generation_config.no_repeat_ngram_size = 3\n",
        "model.generation_config.forced_bos_token_id = tokenizer.bos_token_id\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./pfas_bart_finetuned\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=8,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=3e-5,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/umich 25 WN/CSE 692 Project/BART/5_classes/land_large_dis_bart/bart_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/umich 25 WN/CSE 692 Project/BART/5_classes/bart_model/land_large_dis_bart/bart_model\")"
      ],
      "metadata": {
        "id": "fq0g2McF-4rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test dataset\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "print(test_results)\n",
        "# Compute and print perplexity\n",
        "import math\n",
        "print(f\">>> Test Perplexity: {math.exp(test_results['eval_loss']):.2f}\")\n"
      ],
      "metadata": {
        "id": "fawwmeKaC95x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjfYK5P09_ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/umich 25 WN/CSE 692 Project/BART/5_classes/land_large_dis_bart/bart_model\"\n",
        "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "model.eval().to(\"cuda\")  # or \"cpu\" if no GPU\n"
      ],
      "metadata": {
        "id": "PxCIw5fFeazE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)\n",
        "\n"
      ],
      "metadata": {
        "id": "JQsNu4emejoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for batch in test_loader:\n",
        "    input_ids = batch['input_ids'].to(\"cuda\")\n",
        "    attention_mask = batch['attention_mask'].to(\"cuda\")\n",
        "    labels = batch['labels']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    # Fix starts here: replace -100 with tokenizer.pad_token_id, then decode\n",
        "    labels[labels == -100] = tokenizer.pad_token_id\n",
        "    decoded_refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    predictions.extend(decoded_preds)\n",
        "    references.extend(decoded_refs)\n"
      ],
      "metadata": {
        "id": "LgM9MpQoelV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "results = rouge.compute(predictions=predictions, references=references)\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "z55xKV-8ep-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "# Load BLEU metric\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "\n",
        "formatted_preds = predictions\n",
        "formatted_refs = [[ref] for ref in references]  # single reference per prediction\n",
        "\n",
        "# Compute BLEU\n",
        "bleu_result = bleu.compute(predictions=formatted_preds, references=formatted_refs)\n",
        "print(f\"BLEU score: {bleu_result['bleu']:.4f}\")\n"
      ],
      "metadata": {
        "id": "s5aq-Uzwer8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meteor = evaluate.load(\"meteor\")\n",
        "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "print(meteor_result)\n"
      ],
      "metadata": {
        "id": "w6oufWgSeusr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import score\n",
        "P, R, F1 = score(predictions, references, lang=\"en\", verbose=True)\n",
        "print(f\"BERTScore - P: {P.mean().item():.4f}, R: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n"
      ],
      "metadata": {
        "id": "PWM7q45MevJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}